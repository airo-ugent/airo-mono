{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Point Cloud Performance\n",
    "\n",
    "> Download this data from [here](https://ugentbe-my.sharepoint.com/:f:/g/personal/victorlouis_degusseme_ugent_be/EkIZoyySsnZBg56hRq1BqdkBuGlvhAwPWT9HDuqaUB-psA?e=iSehj6) and save the folder in a folder called `data` relative to this notebook.\n",
    "\n",
    "Main takeaways:\n",
    "* \"Conversion\" is ~instant because array memory is shared.\n",
    "* Filtering time scales with the amount of `True` values in the mask.\n",
    "* Using `&` on mask is fast, so it's better to `&` lots of masks together than to filter sequentially.\n",
    "* Filtering with our dataclass/in numpy is faster than Open3D's `select_by_index` or `select_by_mask`.\n",
    "* Using `.nonzero()` on a boolean array before indexing is faster than using a boolean array directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "data_dir = os.path.join(\"data\", \"competition_sample_0000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls $data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "\n",
    "from airo_typing import NumpyDepthMapType\n",
    "from airo_dataset_tools.data_parsers.camera_intrinsics import CameraIntrinsics\n",
    "from airo_dataset_tools.data_parsers.pose import Pose\n",
    "from airo_camera_toolkit.point_clouds.conversions import open3d_to_point_cloud, point_cloud_to_open3d\n",
    "from airo_camera_toolkit.point_clouds.operations import filter_point_cloud, crop_point_cloud\n",
    "from airo_camera_toolkit.point_clouds.operations import crop_point_cloud_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intrinsics_path = os.path.join(data_dir, \"intrinsics.json\")\n",
    "image_left_path = os.path.join(data_dir, \"image_left.png\")\n",
    "image_right_path = os.path.join(data_dir, \"image_right.png\")\n",
    "depth_map_path = os.path.join(data_dir, \"depth_map.tiff\")\n",
    "confidence_map_path = os.path.join(data_dir, \"confidence_map.tiff\")\n",
    "point_cloud_path = os.path.join(data_dir, \"pointcloud.ply\")\n",
    "camera_pose_path = os.path.join(data_dir, \"camera_pose.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(intrinsics_path, \"r\") as f:\n",
    "    intrinsics_model = CameraIntrinsics.model_validate_json(f.read())\n",
    "    intrinsics = intrinsics_model.as_matrix()\n",
    "    resolution = intrinsics_model.image_resolution.as_tuple()\n",
    "\n",
    "with open(camera_pose_path, \"r\") as f:\n",
    "    camera_pose = Pose.model_validate_json(f.read()).as_homogeneous_matrix()\n",
    "\n",
    "with np.printoptions(precision=3, suppress=True):\n",
    "    print(\"Resolution:\", resolution)\n",
    "    print(\"Intrinsics: \\n\", intrinsics)\n",
    "    print(\"Extrinsics: \\n\", camera_pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize_confidence(image: NumpyDepthMapType, threshold=50.0):\n",
    "    confident = image <= threshold\n",
    "    return confident\n",
    "\n",
    "depth_map = cv2.imread(depth_map_path, cv2.IMREAD_ANYDEPTH)\n",
    "confidence_map = cv2.imread(confidence_map_path, cv2.IMREAD_ANYDEPTH)\n",
    "\n",
    "# Confidence mask\n",
    "threshold = 1.0  # a value of 1.0 means only the most confidence points will be kept\n",
    "confidence_binarized = binarize_confidence(confidence_map, threshold)\n",
    "confidence_mask = confidence_binarized.reshape(-1)\n",
    "\n",
    "# Bounding box\n",
    "bbox = (0.35, -0.3, 0.1), (0.7, 0.1, 0.95)\n",
    "bbox_o3d = o3d.t.geometry.AxisAlignedBoundingBox(*bbox)\n",
    "\n",
    "# Open3D pointclouds\n",
    "pcd_in_camera = o3d.t.io.read_point_cloud(point_cloud_path)\n",
    "\n",
    "# This conversion to float32 can be removed once the data is saved as float32\n",
    "pcd_in_camera.point.positions = o3d.core.Tensor(pcd_in_camera.point.positions.numpy().astype(np.float32))\n",
    "\n",
    "pcd = pcd_in_camera.transform(camera_pose) # transform to world frame (= base frame of left robot)\n",
    "pcd_filtered = pcd.select_by_mask(confidence_mask)\n",
    "pcd_cropped = pcd_filtered.crop(bbox_o3d)\n",
    "\n",
    "# Airo-mono pointclouds\n",
    "point_cloud = open3d_to_point_cloud(pcd)\n",
    "point_cloud_filtered = filter_point_cloud(point_cloud, confidence_mask)\n",
    "point_cloud_cropped = crop_point_cloud(point_cloud_filtered, bbox)\n",
    "\n",
    "pcd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Confidence mask: {100.0 * confidence_mask.mean():.2f}% is True\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance comparison\n",
    "\n",
    "#### Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "point_cloud_to_open3d(point_cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "open3d_to_point_cloud(pcd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "filter_point_cloud(point_cloud, confidence_mask.nonzero()) # adding nonzero() is faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "filter_point_cloud(point_cloud, confidence_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all(point_cloud.points[confidence_mask] == point_cloud.points[confidence_mask.nonzero()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_mask_95_false = confidence_mask.copy()\n",
    "confidence_mask_95_false[:int(0.95 * len(confidence_mask))] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "filter_point_cloud(point_cloud, confidence_mask_95_false.nonzero())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "pcd.select_by_index(np.where(confidence_mask)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "pcd.select_by_mask(confidence_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd_legacy = pcd.to_legacy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "pcd_legacy.select_by_index(np.where(confidence_mask)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "crop_point_cloud(point_cloud_filtered, bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "pcd_filtered.crop(bbox_o3d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "pcd_cropped.voxel_down_sample(voxel_size=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing low confidence points and cropping as fast as possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_mask = crop_point_cloud_mask(point_cloud, bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "crop_mask & confidence_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "crop_mask = crop_point_cloud_mask(point_cloud, bbox)\n",
    "mask = crop_mask & confidence_mask\n",
    "filter_point_cloud(point_cloud, mask.nonzero())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "point_cloud_filtered = filter_point_cloud(point_cloud, confidence_mask.nonzero())\n",
    "point_cloud_cropped = crop_point_cloud(point_cloud_filtered, bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "crop_mask = crop_point_cloud_mask(point_cloud, bbox)\n",
    "mask = crop_mask & confidence_mask\n",
    "pcd.select_by_index(mask.nonzero())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd2 = o3d.t.geometry.PointCloud(pcd)\n",
    "pcd2.point.confidence = o3d.core.Tensor(confidence_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "pcd2_cropped = pcd2.crop(bbox_o3d)\n",
    "pcd2_cropped.select_by_index(pcd2_cropped.point.confidence.numpy().nonzero())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "airo-mono",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
